services:
  ai-hub:
    build: .
    container_name: ai-hub
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
    ports:
      - "4096:4096"  # OpenCode API server (for direct access if needed)
    volumes:
      - ./workdir:/app/workdir      # Mount workspace for code editing
      - ./logs:/app/logs            # Mount logs for persistence
      - ./opencode-auth:/root/.local/share/opencode  # Persist OpenCode auth
    stdin_open: true
    tty: true
    restart: unless-stopped
    networks:
      - ai-hub-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  opencode-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: opencode-webui
    ports:
      - "3001:8080"  # OpenCode WebUI interface
    environment:
      - OPENAI_API_BASE_URL=http://ai-hub:8080/v1
      - OPENAI_API_KEY=dummy-key  # Required but not used with our proxy
      - WEBUI_SECRET_KEY=opencode-ai-hub-secret-key
      - CORS_ALLOW_ORIGIN=*
      - ANONYMIZED_TELEMETRY=false
      - DO_NOT_TRACK=true
      - SCARF_NO_ANALYTICS=true
      - DISABLE_UPDATE_CHECK=true
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
    volumes:
      - ./opencode-webui-data:/app/backend/data
    depends_on:
      ai-hub:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ai-hub-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s

networks:
  ai-hub-network:
    driver: bridge